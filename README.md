# mnist-digits-numpy
The classic exercise of creating a digit classifier using just numpy and math

So far, the only thing that's in this repo is a notebook with my first attempt at this problem, using only the knowledge I gained from watching a YouTube video called "The Complete Mathematics of Neural Networks and Deep Learning" (here: https://www.youtube.com/watch?v=Ixl3nykKG9M). This video walked through the basics of the matrix calculus needed for backpropagation and the equations for a 1-layer neural network with one node per layer using relu activation. It also walked through the basics of how someone might use this math to implement gradient descent. 

My original plan was to finish this task, annotate my notebook with the equations I used, and call it a day. However, I'm shifting my plan to include WAY more iterations of this code before I think about an annotated, polished version. My first attempt model had an accuracy of ~80%. When looking around at other's githubs for ideas about how to format my annotations, I noticed that many of them were getting wayyyy higher accuracies with wayyyyy fewer epochs. So, back to the drawing board. I am going to do some more learning, look at some more resources on this that other people have put out, and iterate on my first solution. 

I'll be back to update! Thanks for reading.
